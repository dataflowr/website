<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/website/css/franklin.css"> <link rel=stylesheet  href="/website/css/poole_hyde.css"> <link rel=stylesheet  href="/website/css/custom.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/website/assets/favicon.png"> <title>Dataflowr - Deep Learning DIY</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img src="/website/assets/dataflowr_violet_plain_square.png" style="width: 120px; height: auto; display: inline"> <img src="/website/assets/favicon.png" style="margin-left:1em; position:relative;left:0px; top:-30px; width: 60px; height: auto; display: inline"> <h1 style="font-size:1em; opacity: 0.95;"><a href="/website/">Deep Learning DIY</a></h1> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/website/modules/0-sotfware-installation"> <b>Module 0</b> - <em> Software installation</em> </a> <a class="sidebar-nav-item " href="/website/modules/1-intro-general-overview"> <b>Module 1</b> - <em>Introduction & General Overview</em> </a> <a class="sidebar-nav-item " href="/website/modules/2a-pytorch-tensors"> <b>Module 2a</b> - <em>PyTorch tensors</em> </a> <a class="sidebar-nav-item " href="/website/modules/2b-automatic-differentiation"> <b>Module 2b</b> - <em>Automatic differentiation</em> </a> <a class="sidebar-nav-item " href="/website/modules/3-loss-functions-for-classification"> <b>Module 3</b> - <em>Loss functions for classification</em> </a> <a class="sidebar-nav-item " href="/website/modules/4-optimization-for-deep-learning"> <b>Module 4</b> - <em>Optimization for DL</em> </a> <a class="sidebar-nav-item " href="/website/modules/5-stacking-layers"> <b>Module 5</b> - <em>Stacking layers</em> </a> <a class="sidebar-nav-item " href="/website/modules/6-convolutional-neural-network"> <b>Module 6</b> - <em>Convolutional neural network</em> </a> <a class="sidebar-nav-item " href="/website/modules/7-dataloading"> <b>Module 7</b> - <em>Dataloading</em> </a> <a class="sidebar-nav-item " href="/website/modules/8a-embedding-layers"> <b>Module 8a</b> - <em>Embedding layers</em> </a> <a class="sidebar-nav-item " href="/website/modules/8b-collaborative-filtering"> <b>Module 8b</b> - <em>Collaborative filtering</em> </a> <a class="sidebar-nav-item " href="/website/modules/8c-word2vec"> <b>Module 8c</b> - <em>Word2vec</em> </a> <a class="sidebar-nav-item " href="/website/modules/9-autoencoders"> <b>Module 9</b> - <em>Autoencoders</em> </a> <a class="sidebar-nav-item " href="/website/modules/10-generative-adversarial-networks"> <b>Module 10</b> - <em>Generative adversarial networks</em> </a> <a class="sidebar-nav-item " href="/website/modules/11a-recurrent-neural-networks-theory"> <b>Module 11a</b> - <em>Recurrent Neural Networks (theory)</em> </a> <a class="sidebar-nav-item " href="/website/modules/11b-recurrent-neural-networks-practice"> <b>Module 11b</b> - <em>RNN in practice</em> </a> <a class="sidebar-nav-item active" href="/website/modules/11c-batches-with-sequences"> <b>Module 11c</b> - <em>Batches with sequences in Pytorch</em> </a> <a class="sidebar-nav-item " href="/website/modules/12-intro-julia"> <b>Module 12</b> - <em>Intro to Julia: Autodiff with dual numbers</em> </a> <a class="sidebar-nav-item " href="/website/modules/13-siamese"> <b>Module 13</b> - <em>Siamese Networks and Representation Learning</em> </a> <a class="sidebar-nav-item " href="/website/modules/14a-depth"> <b>Module 14a</b> - <em>The Benefits of Depth</em> </a> <a class="sidebar-nav-item " href="/website/modules/14b-depth"> <b>Module 14b</b> - <em>The Problems with Depth</em> </a> <a class="sidebar-nav-item " href="/website/modules/15-dropout"> <b>Module 15</b> - <em>Dropout</em> </a> <a class="sidebar-nav-item " href="/website/modules/16-batchnorm"> <b>Module 16</b> - <em>Batchnorm</em> </a> <a class="sidebar-nav-item " href="/website/modules/17-resnets"> <b>Module 17</b> - <em>Resnets</em> </a> <!-- <div class=week >Unit 7</div>--> <div class=week >Homeworks</div> <a class="sidebar-nav-item " href="/website/homework/1-mlp-from-scratch"> <b>Homework 1</b> - <em>MLP from scratch</em> </a> <a class="sidebar-nav-item " href="/website/homework/2-CAM-adversarial"> <b>Homework 2</b> - <em>Class Activation Map and adversarial examples</em> </a> <a class="sidebar-nav-item " href="/website/homework/3-VAE"> <b>Homework 3</b> - <em>VAE for MNIST clustering and generation</em> </a> <div class=week >Bonus</div> <a class="sidebar-nav-item " href="/website/modules/graph0"> <b>Module</b> - <em>Deep learning on graphs</em> </a> <a class="sidebar-nav-item " href="/website/modules/graph1"> <b>Graph</b> - <em>Node embeddings</em> </a> <a class="sidebar-nav-item " href="/website/modules/graph2"> <b>Graph</b> - <em>Signal processing on graphs</em> </a> <a class="sidebar-nav-item " href="/website/modules/graph3"> <b>Graph</b> - <em> Graph embeddings and GNNs</em> </a> <a class="sidebar-nav-item " href="/website/modules/extras/GCN_inductivebias_spectral"> <b>Post</b> - <em>Spectral GCN</em> </a> <a class="sidebar-nav-item " href="/website/modules/extras/Convolutions_first"> <b>Post</b> - <em>Convolutions from first principles</em> </a> <a class="sidebar-nav-item " href="/website/modules/extras/invariant_equivariant"> <b>Post</b> - <em>Invariant and equivariant networks</em> </a> <a class="sidebar-nav-item " href="/website/modules/extras/graph_invariant"> <b>Graph</b> - <em>Exploiting Graph Invariants in Deep Learning</em> </a> <div class=week >Guest Lectures</div> <a class="sidebar-nav-item " href="/website/modules/privacy-preserving-ML"> <b>Privacy Preserving ML</b> - <em>Daniel Huynh</em> </a> </nav> </div> </div> <div class="content container"> <div class=franklin-content ><h1 id=module_11c_-_batches_with_sequences_in_pytorch ><a href="#module_11c_-_batches_with_sequences_in_pytorch" class=header-anchor >Module 11c - Batches with sequences in Pytorch</a></h1> <p><strong>Table of Contents</strong></p> <div class=franklin-toc ><ol><li><a href="#pytorch_tutorial_on_batch_for_sequences">Pytorch tutorial on batch for sequences</a><li><a href="#notebook">Notebook</a></ol></div> <h2 id=pytorch_tutorial_on_batch_for_sequences ><a href="#pytorch_tutorial_on_batch_for_sequences" class=header-anchor >Pytorch tutorial on batch for sequences</a></h2> <p> <div id=videoContainer  > <div id=player ></div> </div> <script> var tag = document.createElement('script'); tag.src = "https://www.youtube.com/iframe_api"; var firstScriptTag = document.getElementsByTagName('script')[0]; firstScriptTag.parentNode.insertBefore(tag, firstScriptTag); var player; function onYouTubeIframeAPIReady() { player = new YT.Player('player', { height: '300', width: '100%', videoId: 'Fqx_RCwenfg', playerVars: { 'autoplay': 0, 'rel': 0, 'cc_load_policy': 1 } }); } function changeYouTubeSource(startTime, endTime) { var youtubeIframe = document.getElementById('player'); var youtubeIframeSrc = document.getElementById('player').getAttribute('src'); var trimmedIframeUrl = ''; var iframeUrlTimeStamp = ''; if (youtubeIframeSrc.match(/&start=/g)) { var mediaFragmentIndex = youtubeIframeSrc.indexOf('&start='); trimmedIframeUrl = youtubeIframeSrc.slice(0, mediaFragmentIndex); if (endTime === 0) { iframeUrlTimeStamp = trimmedIframeUrl + '&start=' + startTime; } else { iframeUrlTimeStamp = trimmedIframeUrl + '&start=' + startTime + '&end=' + endTime; } } if (youtubeIframeSrc.match(/&start=/g) === null) { if (endTime === 0) { iframeUrlTimeStamp = youtubeIframeSrc + '&start=' + startTime; } else { iframeUrlTimeStamp = youtubeIframeSrc + '&start=' + startTime + '&end=' + endTime; } } setTimeout(function() { var iframeAutoplayUrl = iframeUrlTimeStamp.replace('autoplay=0', 'autoplay=1'); youtubeIframe.setAttribute('src', iframeAutoplayUrl); }, 1000); } </script> <br> <a href='#player' onclick='changeYouTubeSource(0,0)'> 0:00</a> Presentation <br> <a href='#player' onclick='changeYouTubeSource(135,0)'> 2:15</a> Step 1: Construct Vocabulary <br> <a href='#player' onclick='changeYouTubeSource(170,0)'> 2:50</a> Step 2: Load indexed data (list of instances, where each instance is list of character indices) <br> <a href='#player' onclick='changeYouTubeSource(225,0)'> 3:45</a> Step 3: Make Model <br> <a href='#player' onclick='changeYouTubeSource(290,0)'> 4:50</a> Step 4: Pad instances with 0s till max length sequence <br> <a href='#player' onclick='changeYouTubeSource(347,0)'> 5:47</a> Step 5: Sort instances by sequence length in descending order <br> <a href='#player' onclick='changeYouTubeSource(415,0)'> 6:55</a> Step 6: Embed the instances <br> <a href='#player' onclick='changeYouTubeSource(550,0)'> 9:10</a> Step 7: Call pack_padded_sequence with embeded instances and sequence lengths <br> <a href='#player' onclick='changeYouTubeSource(761,0)'> 12:41</a> Step 8: Forward with LSTM <br> <a href='#player' onclick='changeYouTubeSource(878,0)'> 14:38</a> Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector </p> <h2 id=notebook ><a href="#notebook" class=header-anchor >Notebook</a></h2> <ul> <li><p><a href="https://github.com/dataflowr/notebooks/blob/master/Module11/11_Tutorial_packing_sequences.ipynb">notebook</a></p> </ul> <div class=page-foot > <div class=copyright > <a href="https://github.com/dataflowr/website/tree/master"><b>Edit this page on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a> Last modified: August 30, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div>